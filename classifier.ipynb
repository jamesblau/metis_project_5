{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd5YVyXOQ_8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pickle\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrDUmZdBVpXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "778dda96-5af3-4791-e0d9-9aef23541aba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRdA96Pd_hjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_dir = \"gdrive/My Drive/metis_project_5\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4XQ-kV6SgQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get easy labels\n",
        "\n",
        "# with open('labels/classifier/easy_labels.csv') as f:\n",
        "#     raw_easy_labels = f.read().split('\\n')[1:-1]\n",
        "\n",
        "# easy_label_regex = re.compile('^([^\\d]*)([^.]*)\\.png,(.*)$')\n",
        "\n",
        "# easy_label_to_int = {'a': 0, 'g': 1, 'db': 2, 'ub': 3, 's': 4}\n",
        "\n",
        "# easy_paths, easy_y = [], []\n",
        "# for label in raw_easy_labels:\n",
        "#     (category, frame, label) = label_regex.match(label).groups()\n",
        "#     int_label = label_to_int.get(label)\n",
        "#     if int_label and category == 'new_fox_':\n",
        "#         path = f\"data/larger_cropped/{frame}.png\"\n",
        "#         easy_paths.append(path)\n",
        "#         easy_y.append(int_label)\n",
        "\n",
        "# easy_num_categories = 5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_VVlEc0SlV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec2c63fe-d53c-4dc9-a140-79995de0abe2"
      },
      "source": [
        "# Get new easy_larger_cropped labels, wiz_sfat\n",
        "\n",
        "with open(f\"{project_dir}/labels/classifier/easy_wiz_sfat_larger_cropped_labels.csv\") as f:\n",
        "    raw_ws_labels = f.read().split('\\n')[1:-1]\n",
        "\n",
        "ws_label_regex = re.compile('^([^.]*)\\.png,(.*)$')\n",
        "\n",
        "ws_label_to_int = {\n",
        "    'g': 0,\n",
        "    'a': 1,\n",
        "    's': 0,\n",
        "    'aub': 1,\n",
        "    'gdb': 0,\n",
        "    'adb': 1,\n",
        "    'l': 1,\n",
        "}\n",
        "ws_num_categories = 2\n",
        "\n",
        "ws_paths, ws_labels, ws_y = [], [], []\n",
        "for label in raw_ws_labels:\n",
        "    frame, label = ws_label_regex.match(label).groups()\n",
        "    if label in ws_label_to_int.keys():\n",
        "        int_label = ws_label_to_int[label]\n",
        "        if int_label:\n",
        "            ws_labels.append('a')\n",
        "        else:\n",
        "            ws_labels.append('g')\n",
        "        path = f\"{project_dir}/data/wiz_sfat/larger_cropped/{frame}.png\"\n",
        "        ws_paths.append(path)\n",
        "        ws_y.append(int_label)\n",
        "\n",
        "print(Counter(ws_labels))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'g': 212, 'a': 136})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_MKj6gu3WgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bed43c74-6f1e-49ff-d505-e3d6a114057a"
      },
      "source": [
        "# Get semi- easy_larger_cropped labels, wiz_sfat\n",
        "\n",
        "with open(f\"{project_dir}/labels/classifier/easy_wiz_sfat_larger_cropped_labels.csv\") as f:\n",
        "    raw_se_labels = f.read().split('\\n')[1:-1]\n",
        "\n",
        "se_label_regex = re.compile('^([^.]*)\\.png,(.*)$')\n",
        "\n",
        "se_label_to_int = {\n",
        "    'g': 0,\n",
        "    'a': 1,\n",
        "    's': 2,\n",
        "    'aub': 3,\n",
        "    'gdb': 4,\n",
        "    'adb': 4,\n",
        "    'l': 5,\n",
        "}\n",
        "se_num_categories = 6\n",
        "\n",
        "se_paths, se_labels, se_y = [], [], []\n",
        "for label in raw_se_labels:\n",
        "    frame, label = se_label_regex.match(label).groups()\n",
        "    se_labels.append(label)\n",
        "    if label in se_label_to_int.keys():\n",
        "        int_label = se_label_to_int[label]\n",
        "        path = f\"{project_dir}/data/wiz_sfat/larger_cropped/{frame}.png\"\n",
        "        se_paths.append(path)\n",
        "        se_y.append(int_label)\n",
        "\n",
        "print(Counter(se_labels))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'g': 200, 'a': 128, 's': 7, 'gdb': 5, 'aub': 5, 'adb': 2, 'l': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHz04FDBh_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc7f1045-28c1-4759-88c3-de014a7dc639"
      },
      "source": [
        "# Get hard labels, wiz_sfat\n",
        "\n",
        "with open(f\"{project_dir}/labels/classifier/hard_wiz_sfat_labels.csv\") as f:\n",
        "    raw_hws_labels = f.read().split('\\n')[1:-1]\n",
        "\n",
        "hws_label_regex = re.compile('^([^\\d]*)([^.]*)\\.png,.,(.*)$')\n",
        "\n",
        "hws_label_to_int = {\n",
        "    'a': 0,\n",
        "    'adb': 1,\n",
        "    'anb': 2,\n",
        "    'aub': 3,\n",
        "    'ba': 4,\n",
        "    'd': 5,\n",
        "    'da': 6,\n",
        "    'dt': 7,\n",
        "    'g': 8,\n",
        "    'gdb': 9,\n",
        "    'h': 10,\n",
        "    'ha': 12,\n",
        "    'hg': 12,\n",
        "    'j': 13,\n",
        "    'l': 14,\n",
        "    'na': 15,\n",
        "    'p': 16,\n",
        "    's': 17,\n",
        "    'sd': 18,\n",
        "    't': 19,\n",
        "    'ua': 20,\n",
        "    'ut': 21,\n",
        "}\n",
        "hws_num_categories = 22\n",
        "\n",
        "hws_paths, hws_labels, hws_y = [], [], []\n",
        "for label in raw_hws_labels:\n",
        "    (category, frame, label) = hws_label_regex.match(label).groups()\n",
        "    int_label = hws_label_to_int.get(label)\n",
        "    hws_labels.append(label)\n",
        "    if int_label and category == 'new_fox_':\n",
        "        int_label = hws_label_to_int[label]\n",
        "        path = f\"{project_dir}/data/wiz_sfat/larger_cropped/{frame}.png\"\n",
        "        hws_paths.append(path)\n",
        "        hws_y.append(int_label)\n",
        "\n",
        "print(Counter(hws_labels))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'g': 263, 'a': 175, 'ha': 20, 'ba': 15, 'na': 14, 'ut': 9, 'gdb': 7, 's': 7, 'd': 6, 'da': 5, 'aub': 5, 'hg': 3, 'l': 3, 'ub': 3, 'adb': 2, 'anb': 2, 'ua': 2, 'h': 2, 't': 1, 'p': 1, 'sd': 1, 'dt': 1, 'j': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxzCnWSDm2EE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5c5418f-b814-47c5-9001-93a7938c4b21"
      },
      "source": [
        "# Get easy labels, tbh7_purp_fox_vgbc\n",
        "\n",
        "with open(f\"{project_dir}/labels/classifier/easy_tbh7_purp_fox_vgbc_labels.csv\") as f:\n",
        "    raw_tbh_labels = f.read().split('\\n')[1:-1]\n",
        "\n",
        "tbh_label_regex = re.compile('^([^.]*)\\.png,(.*)$')\n",
        "\n",
        "tbh_label_to_int = {\n",
        "    'g': 0,\n",
        "    'a': 1,\n",
        "    's': 0,\n",
        "    'aub': 1,\n",
        "    'gdb': 0,\n",
        "    'adb': 1,\n",
        "    'l': 1,\n",
        "}\n",
        "tbh_num_categories = 2\n",
        "\n",
        "# tbh_label_to_int = {\n",
        "#     'g': 0,\n",
        "#     'a': 1,\n",
        "#     's': 2,\n",
        "#     'aub': 3,\n",
        "#     'gdb': 4,\n",
        "#     'adb': 5,\n",
        "#     'l': 6,\n",
        "# }\n",
        "# tbh_num_categories = 7\n",
        "\n",
        "tbh_paths, tbh_labels, tbh_y = [], [], []\n",
        "for label in raw_tbh_labels:\n",
        "    frame, label = tbh_label_regex.match(label).groups()\n",
        "    tbh_labels.append(label)\n",
        "    if label in tbh_label_to_int.keys():\n",
        "        int_label = tbh_label_to_int[label]\n",
        "        path = f\"{project_dir}/data/tbh7_purp_fox_vgbc/larger_cropped/{frame}.png\"\n",
        "        tbh_paths.append(path)\n",
        "        tbh_y.append(int_label)\n",
        "\n",
        "print(Counter(tbh_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'g': 187, 'a': 173, 'aub': 18, 'l': 10, 's': 6, 'adb': 3, 'gdb': 3})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nRT25jsugJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_hw = (350, 350)\n",
        "img_dimensions = (350, 350, 3)\n",
        "\n",
        "def prepare_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=img_hw)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    # x = mobilenet_v2.preprocess_input(x)\n",
        "    return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE6I7qmTTHIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test/train data, wiz_sfat easy\n",
        "\n",
        "ws_X = np.array([prepare_image(path)[0] for path in ws_paths])\n",
        "\n",
        "ws_X_tr, ws_X_te, ws_y_tr, ws_y_te = train_test_split(ws_X, ws_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaBgBYob7lEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test/train data, wiz_sfat semi-easy\n",
        "\n",
        "se_X = np.array([prepare_image(path)[0] for path in se_paths])\n",
        "\n",
        "se_X_tr, se_X_te, se_y_tr, se_y_te = train_test_split(se_X, se_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhpUilum2hLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test/train data, wiz_sfat hard\n",
        "\n",
        "hws_X = np.array([prepare_image(path)[0] for path in hws_paths])\n",
        "\n",
        "hws_X_tr, hws_X_te, hws_y_tr, hws_y_te = train_test_split(hws_X, hws_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tPo99ntuFwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test/train data, tbh7\n",
        "\n",
        "tbh_X = np.array([prepare_image(path)[0] for path in tbh_paths])\n",
        "\n",
        "tbh_X_tr, tbh_X_te, tbh_y_tr, tbh_y_te = train_test_split(tbh_X, tbh_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzWhMxvHAn00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "1493de1c-dd7a-4ca9-8e1b-cbd7da05b0f0"
      },
      "source": [
        "pickles_dir = project_dir + \"/pickles\"\n",
        "\n",
        "!ls gdrive/My\\ Drive/metis_project_5/pickles"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_1.pickle\t tbh_y_tr_cat.pickle  ws_y_te.pickle\t  X_tr.pickle\n",
            "tbh_X_te.pickle  tbh_y_tr.pickle      ws_y_tr_cat.pickle  y_te.pickle\n",
            "tbh_X_tr.pickle  ws_X_te.pickle       ws_y_tr.pickle\t  y_tr_cat.pickle\n",
            "tbh_y_te.pickle  ws_X_tr.pickle       X_te.pickle\t  y_tr.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYmEhGwCX6wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump easy wiz_sfat data\n",
        "\n",
        "# with open(f'{pickles_dir}/ws_X_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(ws_X_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/ws_X_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(ws_X_te, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/ws_y_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(ws_y_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/ws_y_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(ws_y_te, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6h3hn6oBiYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load easy wiz_sfat data\n",
        "\n",
        "with open(f'{pickles_dir}/ws_X_tr.pickle', 'rb') as f:\n",
        "    ws_X_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/ws_X_te.pickle', 'rb') as f:\n",
        "    ws_X_te = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/ws_y_tr.pickle', 'rb') as f:\n",
        "    ws_y_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/ws_y_te.pickle', 'rb') as f:\n",
        "    ws_y_te = pickle.load(f)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ12XyBW8SQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump semi-easy wiz_sfat data\n",
        "\n",
        "# with open(f'{pickles_dir}/se_X_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(se_X_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/se_X_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(se_X_te, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/se_y_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(se_y_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/se_y_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(se_y_te, f)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzVQfOs98ast",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load semi-easy wiz_sfat data\n",
        "\n",
        "with open(f'{pickles_dir}/se_X_tr.pickle', 'rb') as f:\n",
        "    se_X_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/se_X_te.pickle', 'rb') as f:\n",
        "    se_X_te = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/se_y_tr.pickle', 'rb') as f:\n",
        "    se_y_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/se_y_te.pickle', 'rb') as f:\n",
        "    se_y_te = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOvhk-U39SZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump hard wiz_sfat data\n",
        "\n",
        "# with open(f'{pickles_dir}/hws_X_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(hws_X_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/hws_X_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(hws_X_te, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/hws_y_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(hws_y_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/hws_y_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(hws_y_te, f)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TEX0pLW9byh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load hard wiz_sfat data\n",
        "\n",
        "with open(f'{pickles_dir}/hws_X_tr.pickle', 'rb') as f:\n",
        "    hws_X_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/hws_X_te.pickle', 'rb') as f:\n",
        "    hws_X_te = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/hws_y_tr.pickle', 'rb') as f:\n",
        "    hws_y_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/hws_y_te.pickle', 'rb') as f:\n",
        "    hws_y_te = pickle.load(f)"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdNEJwybxTi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump easy tbh data\n",
        "\n",
        "# with open(f'{pickles_dir}/tbh_X_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(tbh_X_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/tbh_X_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(tbh_X_te, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/tbh_y_tr.pickle', 'wb') as f:\n",
        "#     pickle.dump(tbh_y_tr, f)\n",
        "\n",
        "# with open(f'{pickles_dir}/tbh_y_te.pickle', 'wb') as f:\n",
        "#     pickle.dump(tbh_y_te, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0McDFoqxU8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load easy tbh data\n",
        "\n",
        "with open(f'{pickles_dir}/tbh_X_tr.pickle', 'rb') as f:\n",
        "    tbh_X_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/tbh_X_te.pickle', 'rb') as f:\n",
        "    tbh_X_te = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/tbh_y_tr.pickle', 'rb') as f:\n",
        "    tbh_y_tr = pickle.load(f)\n",
        "\n",
        "with open(f'{pickles_dir}/tbh_y_te.pickle', 'rb') as f:\n",
        "    tbh_y_te = pickle.load(f)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7uBCvpHCe33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose actual training and test sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNecpGuuHBqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on semi-easy labels with wiz_sfat images\n",
        "X_tr = se_X_tr\n",
        "y_tr = se_y_tr\n",
        "X_te = se_X_te\n",
        "y_te = se_y_te\n",
        "num_categories = se_num_categories"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eazPQrRzIEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on tbh images (larger set) and test on wiz_sfat images\n",
        "X_tr = np.concatenate([tbh_X_tr, tbh_X_te])\n",
        "y_tr = tbh_y_tr + tbh_y_te\n",
        "X_te, y_te = ws_X_te, ws_y_te\n",
        "num_categories = tbh_num_categories"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdmxY3Kr1H4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on both train sets and test on both test sets\n",
        "X_tr = np.concatenate([tbh_X_tr, ws_X_tr])\n",
        "y_tr = tbh_y_tr + ws_y_tr\n",
        "X_te = np.concatenate([tbh_X_te, ws_X_te])\n",
        "y_te = tbh_y_te + ws_y_te\n",
        "num_categories = ws_num_categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stJSYWHUS__4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on hard labels with wiz_sfat images\n",
        "X_tr = hws_X_tr\n",
        "y_tr = hws_y_tr\n",
        "X_te = hws_X_te\n",
        "y_te = hws_y_te\n",
        "num_categories = hws_num_categories"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ItD4qSaIjm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If multi-class, make categorical targets\n",
        "if num_categories > 2:\n",
        "  y_tr_cat_compare = np_utils.to_categorical(y_tr)\n",
        "  num_tr = len(y_tr)\n",
        "  y = np.concatenate([y_tr, y_te])\n",
        "  y_cat = np_utils.to_categorical(y)\n",
        "  y_tr_cat = y_cat[:num_tr]\n",
        "  y_te_cat = y_cat[num_tr:]\n",
        "  assert(len(np.concatenate([y_tr_cat, y_te_cat])) == len(y))\n",
        "  assert(len(y_tr) == len(y_tr_cat))\n",
        "  assert(len(y_te) == len(y_te_cat))\n",
        "  assert((y_tr_cat == y_tr_cat_compare).all())\n",
        "else:\n",
        "  y_tr_cat = y_tr\n",
        "  y_te_cat = y_te"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZVKZ5-Wf3xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch pretrained model\n",
        "\n",
        "pretrained = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=img_dimensions,\n",
        ")"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXq83hbOgYMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "978b5323-ab1c-40f0-935c-254e77fa05d5"
      },
      "source": [
        "# Build model\n",
        "\n",
        "for layer in pretrained.layers[:17]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(pretrained)\n",
        "model.add(Flatten())\n",
        "\n",
        "if num_categories > 2:\n",
        "    model.add(Dense(num_categories))\n",
        "    loss='categorical_crossentropy',\n",
        "else:\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    loss='binary_crossentropy',\n",
        "\n",
        "model.compile(\n",
        "    loss=loss,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 10, 10, 512)       14714688  \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 22)                1126422   \n",
            "=================================================================\n",
            "Total params: 15,841,110\n",
            "Trainable params: 3,486,230\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfIJ7pCF2BiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image augmentation\n",
        "tr_datagen = image.ImageDataGenerator()\n",
        "    # rescale=1./255,\n",
        "    # featurewise_std_normalization=True,\n",
        "    # vertical_flip=True,\n",
        "    # validation_split=0.25)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPsxZJX24Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only applying scaling to the validation set\n",
        "# te_datagen = ImageDataGenerator(rescale=1./255)\n",
        "te_datagen = tr_datagen"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eoTJvFa2-Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training and test gerators\n",
        "tr_gen = tr_datagen.flow(X_tr, y_tr_cat)\n",
        "te_gen = te_datagen.flow(X_te, y_te_cat)\n",
        "epochs=100\n",
        "\n",
        "# Callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1,\n",
        "                   restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.2,\n",
        "                   patience=10, cooldown=5, min_lr=0.0002)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMA-nJJlNr3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "b03709cd-c365-4f8a-d892-f7457fdacdf1"
      },
      "source": [
        "# Train model\n",
        "model.fit_generator(tr_gen, steps_per_epoch=10, epochs=epochs, callbacks=[es, reduce_lr], \n",
        "                 verbose=1, validation_data=te_gen, validation_steps=20)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 26s 3s/step - loss: 9.2231 - accuracy: 0.3979 - val_loss: 12.2476 - val_accuracy: 0.6923\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 19s 2s/step - loss: 13.1492 - accuracy: 0.6523 - val_loss: 14.0881 - val_accuracy: 0.6923\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 19s 2s/step - loss: 12.3601 - accuracy: 0.6303 - val_loss: 13.3536 - val_accuracy: 0.6923\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 19s 2s/step - loss: 12.7653 - accuracy: 0.6391 - val_loss: 11.7866 - val_accuracy: 0.6923\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 19s 2s/step - loss: 9.6285 - accuracy: 0.6408 - val_loss: 0.8059 - val_accuracy: 0.6923\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 20s 2s/step - loss: 10.6542 - accuracy: 0.6313 - val_loss: 2.4177 - val_accuracy: 0.6923\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 19s 2s/step - loss: 4.1013 - accuracy: 0.6444 - val_loss: 4.0295 - val_accuracy: 0.6923\n",
            "Epoch 8/100\n",
            " 6/10 [=================>............] - ETA: 2s - loss: 4.8258 - accuracy: 0.6379"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-211-d6d04f3d597a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(tr_gen, steps_per_epoch=10, epochs=epochs, callbacks=[es, reduce_lr], \n\u001b[0;32m----> 3\u001b[0;31m                  verbose=1, validation_data=te_gen, validation_steps=20)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTpcolkTQFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "992406e0-44bd-4036-d714-30421c7bdcb7"
      },
      "source": [
        "# Train model\n",
        "\n",
        "for _ in range(1):\n",
        "  if num_categories > 2:\n",
        "      model.fit(X_tr, y_tr_cat)\n",
        "  else:\n",
        "      model.fit(X_tr, y_tr)\n",
        "      y_pr = model.predict_classes(X_te)[:,0]\n",
        "      print(f\"Test accuracy: {len(y_pr[y_pr == y_te]) / len(y_pr)}\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "278/278 [==============================] - 7s 24ms/step - loss: 9.5555 - accuracy: 0.5504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ch0xnIDj0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save / load model\n",
        "\n",
        "models_dir = project_dir + \"/models\"\n",
        "!mkdir -p gdrive/My\\ Drive/metis_project_5/models\n",
        "\n",
        "models = glob(models_dir + '/*')\n",
        "latest_model_num = int(re.sub(\".*model_(\\d*)\\..*\", \"\\\\1\", sorted(models)[-1]))\n",
        "next_model_num = latest_model_num + 1"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E10r8jmFKYHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(f'{models_dir}/model_{next_model_num}.hdf5')"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vZ8FcynLcDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(f'{models_dir}/model_{next_model_num}.hdf5')\n",
        "# model.load_weights(f'{models_dir}/model_{latest_model_num}.hdf5')"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALa-UmOXKl81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5be55c6-a1b5-4c86-9535-eefd55cfe8d2"
      },
      "source": [
        "pretrained.weights[0][0][0][0][0]"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.00040788297>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47xyoJjjKm-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02dc6a32-edf0-4d65-9c5f-e3778579dfe1"
      },
      "source": [
        "pretrained.weights[0][0][0][0][0]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-0.0012804723>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFvsihZmF_Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "46af049d-6cf8-49a8-c917-86efb7507e3f"
      },
      "source": [
        "print(f\"Train zeros: {len(list(filter(lambda x: x == 0, y_tr)))}\")\n",
        "print(f\"Train ones: {len(list(filter(lambda x: x == 1, y_tr)))}\")\n",
        "print(f\"Test zeros: {len(list(filter(lambda x: x == 0, y_te)))}\")\n",
        "print(f\"Test ones: {len(list(filter(lambda x: x == 1, y_te)))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train zeros: 168\n",
            "Train ones: 109\n",
            "Test zeros: 44\n",
            "Test ones: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7tONMQFxga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for x in zip(y_pr, y_te):\n",
        "#   print(x)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuLXz5lHTTCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f714fdd5-6080-40ec-cec8-6c32fd23e4d2"
      },
      "source": [
        "# Predict and score\n",
        "\n",
        "y_pr = model.predict_classes(X_te)[:,0]\n",
        "\n",
        "print(f\"Test accuracy: {len(y_pr[y_pr == y_te]) / len(y_pr)}\")\n",
        "\n",
        "assert(len(y_pr) == len(y_te))\n",
        "\n",
        "y_tr_pr = model.predict_classes(X_tr)[:,0]\n",
        "\n",
        "print(f\"Train accuracy: {len(y_tr_pr[y_tr_pr == y_tr]) / len(y_tr_pr)}\")\n",
        "\n",
        "assert(len(y_tr_pr) == len(y_tr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8285714285714286\n",
            "Train accuracy: 0.9566787003610109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRAZcDeEjUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(y_pr)\n",
        "# print(y_te)\n",
        "# print(y_tr_pr)\n",
        "# print(y_tr)"
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}